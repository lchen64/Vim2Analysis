{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tables\n",
    "import skimage.transform as st\n",
    "\n",
    "chunk_number = 400\n",
    "chunk_length = 16\n",
    "C3D_input_size = 112\n",
    "sliding_window_size = 16\n",
    "sliding_window_stride = 1\n",
    "number_of_windows = 107985\n",
    "num_windows_test = 8100 - 15\n",
    "original_size = 128\n",
    "number_of_frame_to_load = number_of_windows -  sliding_window_size + 1\n",
    "\n",
    "resized_stimulus_path = \"./resized_stimulus.npy\"\n",
    "extracted_features_path = \"./extracted_features.npy\"\n",
    "extracted_features_path_test = \"./extracted_features_test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprintProgressBar(0, 10, prefix = 'Prefix:', suffix = 'Complete', length = 20)\\nfor i in range(10):\\n    # Do something\\n    printProgressBar(i + 1, 10, prefix = 'Prefix:', suffix = 'Complete', length = 20)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'x'):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()\n",
    "        \n",
    "'''\n",
    "printProgressBar(0, 10, prefix = 'Prefix:', suffix = 'Complete', length = 20)\n",
    "for i in range(10):\n",
    "    # Do something\n",
    "    printProgressBar(i + 1, 10, prefix = 'Prefix:', suffix = 'Complete', length = 20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus Loaded. Shape:(108000, 3, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#    Load Dataset    #\n",
    "######################\n",
    "\n",
    "def roi_index(region, file):\n",
    "\troi = file.get_node('/roi/v1lh')[:].flatten()\n",
    "\treturn np.nonzero(roi==region)[0] \n",
    "\n",
    "def load_train_stimulus():\n",
    "\tstimuli = tables.open_file('Stimuli.mat')\n",
    "\treturn stimuli.get_node('/st')[:]\n",
    "\n",
    "def load_train_response(subject, roi):\n",
    "\tpath = \"VoxelResponses_subject\" + subject + \".mat\"\n",
    "\tresponse = tables.open_file(path) \n",
    "\tdata = response.get_node('/rt')[:]\n",
    "\treturn data[roi_index(roi, response)]\n",
    "\n",
    "def load_train_response_all(subject):\n",
    "\tpath = \"VoxelResponses_subject\" + subject + \".mat\"\n",
    "\tresponse = tables.open_file(path) \n",
    "\tdata = response.get_node('/rt')[:]\n",
    "\treturn data\n",
    "\n",
    "def load_validation_stimulus():\n",
    "\tstimuli = tables.open_file('Stimuli.mat')\n",
    "\treturn stimuli.get_node('/sv')[:]\n",
    "\n",
    "def load_validation_response(subject, roi):\n",
    "\tpath = \"VoxelResponses_subject\" + subject + \".mat\"\n",
    "\tresponse = tables.open_file(path) \n",
    "\tdata = response.get_node('/rv')[:]\n",
    "\treturn data[roi_index(roi, response)]\n",
    "\n",
    "def load_validation_response_all(subject):\n",
    "\tpath = \"VoxelResponses_subject\" + subject + \".mat\"\n",
    "\tresponse = tables.open_file(path) \n",
    "\tdata = response.get_node('/rv')[:]\n",
    "\treturn data\n",
    "\n",
    "stimulus_train = load_train_stimulus()\n",
    "print(\"Stimulus Loaded. Shape:\" + str(stimulus_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m model_from_json\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout, Flatten\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconvolutional\u001b[39;00m \u001b[39mimport\u001b[39;00m Convolution3D, MaxPooling3D, ZeroPadding3D\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m SGD\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.core'"
     ]
    }
   ],
   "source": [
    "######################\n",
    "#     Load Model     #\n",
    "######################\n",
    "\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "\n",
    "def create_model():\n",
    "    \"\"\" Creates model object with the sequential API:\n",
    "    https://keras.io/models/sequential/\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    input_shape = (16, 112, 112, 3)\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv1',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           padding='valid', name='pool1'))\n",
    "    # 2nd layer group\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool2'))\n",
    "    # 3rd layer group\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3a'))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool3'))\n",
    "    # 4th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4a'))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool4'))\n",
    "    # 5th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5a'))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5b'))\n",
    "    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    # FC layers group\n",
    "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(487, activation='softmax', name='fc8'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def intermediate_layer_model(layer, model):\n",
    "\n",
    " \treturn Model(inputs=model.input, outputs=model.get_layer(layer).output)\n",
    "\n",
    "def feature_hook(layer, model, data):\n",
    "\n",
    "\tmodel = intermediate_layer_model(layer, model)\n",
    "\treturn model(data)\n",
    "\n",
    "def create_features_extractor(model, layer_name):\n",
    "    extractor = Model(inputs= model.input,\n",
    "                      outputs= model.get_layer(layer_name).output)\n",
    "    return extractor\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(\"c3d-sports1M_weights.h5\")\n",
    "print(\"Weight loaded\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1_input (InputLayer)     (None, 16, 112, 112, 3)   0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "=================================================================\n",
      "Total params: 27,655,936\n",
      "Trainable params: 27,655,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Pick a layer to create extractor  #\n",
    "#####################################\n",
    "output_layer_name = 'flatten_1'\n",
    "extractor = create_features_extractor(model,output_layer_name)\n",
    "extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to extract feature. Expected output:{},{} 107985 8192\n",
      "Progress: |xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx| 100.0% \n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#   Extract TrainSet Features  #\n",
    "################################\n",
    "\n",
    "#extracted_feature = np.zeros((number_of_windows,extractor.output.shape[1]))\n",
    "extracted_feature = np.zeros((number_of_windows,8192))\n",
    "\n",
    "print(\"Starting to extract features. Expected output:\" + str(extracted_feature.shape))\n",
    "printProgressBar(0, number_of_windows, prefix = 'Progress:', suffix = '', length = 100)\n",
    "for i in range(number_of_windows):\n",
    "    chunk = stimulus_train[i:i+sliding_window_size, :,:,:]\n",
    "    chunk_transposed = np.transpose(chunk,(0,2,3,1))\n",
    "    chunk_resized = st.resize(chunk_transposed, (sliding_window_size,C3D_input_size, C3D_input_size,3))\n",
    "    to_be_fed = np.zeros((1,sliding_window_size, C3D_input_size, C3D_input_size, 3))\n",
    "    to_be_fed[0,:,:,:,:] = chunk_resized\n",
    "    extracted_feature[i,:] = extractor.predict(to_be_fed)\n",
    "    printProgressBar(i + 1, number_of_windows, prefix = 'Progress:', suffix = '', length = 100)\n",
    "\n",
    "#save to file\n",
    "np.save(extracted_features_path,extracted_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107985, 8192)\n",
      "0.0047931513831026085\n"
     ]
    }
   ],
   "source": [
    "checking = np.load(extracted_features_path)\n",
    "print(str(checking.shape))\n",
    "print(str(checking.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_test = load_validation_stimulus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to extract feature. Expected output:(8085, 8192)\n",
      "Progress: |xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx| 100.0% \n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "#   Extract Test Features  #\n",
    "#############################\n",
    "\n",
    "#extracted_feature = np.zeros((number_of_windows,extractor.output.shape[1]))\n",
    "extracted_feature = np.zeros((num_windows_test, 8192))\n",
    "\n",
    "print(\"Starting to extract feature. Expected output:\" + str(extracted_feature.shape))\n",
    "printProgressBar(0, num_windows_test, prefix = 'Progress:', suffix = '', length = 100)\n",
    "for i in range(num_windows_test):\n",
    "    chunk = stimulus_test[i:i+sliding_window_size, :,:,:]\n",
    "    chunk_transposed = np.transpose(chunk,(0,2,3,1))\n",
    "    chunk_resized = st.resize(chunk_transposed, (sliding_window_size, C3D_input_size, C3D_input_size,3))\n",
    "    to_be_fed = np.zeros((1,sliding_window_size, C3D_input_size, C3D_input_size, 3))\n",
    "    to_be_fed[0,:,:,:,:] = chunk_resized\n",
    "    extracted_feature[i,:] = extractor.predict(to_be_fed)\n",
    "    printProgressBar(i + 1, num_windows_test, prefix = 'Progress:', suffix = '', length = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "np.save(extracted_features_path_test, extracted_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8085, 8192)\n"
     ]
    }
   ],
   "source": [
    "print(str(extracted_feature.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
